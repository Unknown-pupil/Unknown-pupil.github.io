<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>模型评估与选择</title>
      <link href="/2019/07/15/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"/>
      <url>/2019/07/15/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><h2 id="误差"><a href="#误差" class="headerlink" title="误差"></a>误差</h2><h3 id="误差-1"><a href="#误差-1" class="headerlink" title="误差"></a>误差</h3><p>误差（Error）：是模型的预测输出值与其真实值之间的差异。</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练（Training）：通过已知的样本数据进行学习，从而得到模型的过程。</p><h3 id="训练误差"><a href="#训练误差" class="headerlink" title="训练误差"></a>训练误差</h3><p>训练误差（Training Error）：模型作用于训练集时的误差。</p><h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p>泛化（Generalize）：由具体的、个别的扩大为一般的，即从特殊到一般，称为泛化。对机器学习的模型来讲，泛化是指模型作用于新的样本数据（非训练集）。</p><h3 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h3><p>泛化误差（Generalize Error）：模型作用于新的样本数据时的误差。</p><p><img src="/images/8166116-bd9e4acdf2460fa3.png" alt></p><hr><h2 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h2><h3 id="模型容量"><a href="#模型容量" class="headerlink" title="模型容量"></a>模型容量</h3><p>模型容量（Model Capacity）：是指其你和各种模型的能力。</p><h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>过拟合（Overfitting）：是某个模型在训练集上表现得很好，但是在新样本上表现差。模型将训练集的特征学习得太好，导致一些非普遍规律被模型接纳和体现，从而在训练集上表现好，但是对于新样本表现差，反之则称为欠拟合（Underfitting），即模型对训练集的一半性质学习较差，模型作用于训练集时表现不好。</p><h2 id="模型选择-1"><a href="#模型选择-1" class="headerlink" title="模型选择"></a>模型选择</h2><p>模型选择（Model Selection）：针对某个具体的任务，通常会有多种模型可供选择，对同一个模型也会有多组参数，可以通过分析、评估模型的泛化误差，选择泛化误差最小的模型。</p><p>选择图中红线位置的模型：</p><p><img src="/images/8166116-bd9e4acdf2460f223.png" alt></p><hr><h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><h2 id="评估思路"><a href="#评估思路" class="headerlink" title="评估思路"></a>评估思路</h2><p>通过实验测试，对模型的泛化误差进行评估，选出泛化误差最小的耳模型。待测数据集全集未知，使用测试集进行泛化测试，测试误差（Testing Error）即为泛化误差近似。</p><p><img src="/images/8166116-bd9e4acderdsa3.png" alt></p><hr><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><h3 id="1-留出法"><a href="#1-留出法" class="headerlink" title="1. 留出法"></a>1. 留出法</h3><p>留出法（Hold-out）：将已知数据集分成两个互斥的部分，其中一部分用来训练模型，另一部分用来测试模型，评估其误差，作为泛化误差的估计。</p><ul><li><p><strong>两个数据集的划分要尽可能保持数据分布一致性，避免因数据划分过程引入为的偏差。</strong></p></li><li><p><strong>数据分割存在多种形式会导致不同的训练集、测试集划分，单次留出法结果往往存在偶然性，其稳定性较差，通常会进行若干次随机划分、重复实验评估取平均值作为评估结果。</strong></p></li><li><p><strong>数据集拆分成两部分，每部分的规模设置回影响评估结果，测试、训练的比例通常为7:3、8:2等</strong></p></li></ul><h3 id="2-交叉验证法"><a href="#2-交叉验证法" class="headerlink" title="2. 交叉验证法"></a>2. 交叉验证法</h3><p>交叉验证法（Cross Validation）：将数据集划分k个大小相似的互斥的数据子集，子集数据尽可能保证数据分布的一致性（分层采样），每次从中选取一个数据集作为测试集，其余用作训练集，可以进行k次训练和测试，得到评估均值。该验证方法也称作k折交叉验证（k-fold Cross Validation）。使用不同划分，重复p次，称为p次k折交叉验证。</p><p><img src="/images/8166116-bd9e4acdf24634fa2.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习方法总结</title>
      <link href="/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="机器学习的基本概念"><a href="#机器学习的基本概念" class="headerlink" title="机器学习的基本概念"></a>机器学习的基本概念</h2><h3 id="输入空间"><a href="#输入空间" class="headerlink" title="输入空间"></a>输入空间</h3><p>输入‘X’可能取值的集合就是输入空间（input space）。输入空间可以是有限集合空间，也可以是整个欧式空间。</p><h3 id="输出空间"><a href="#输出空间" class="headerlink" title="输出空间"></a>输出空间</h3><p>输出‘Y’可能取值的集合就是输出空间（output space）。输出空间可以是有限集合空间，也可以是整个欧式空间。</p><h3 id="假设空间"><a href="#假设空间" class="headerlink" title="假设空间"></a>假设空间</h3><p>假设空间一般是对于学习到的模型而言的。模型表达了输入到输出的一种映射集合，这个集合就是假设空间，假设空间表明着模型学习的范围。</p><h3 id="特征空间"><a href="#特征空间" class="headerlink" title="特征空间"></a>特征空间</h3><p>每一条样本被称作是一个实例，通常由特征向量表示，所有特征向量存在的空间称为特征空间。特征空间有时候与输入空间相同，有时候不同（例如word embbeding），不同的情况是输入空间通过某种映射生成了特征空间。</p><hr><h2 id="机器学习的实质"><a href="#机器学习的实质" class="headerlink" title="机器学习的实质"></a>机器学习的实质</h2><p>在输入空间到输出空间中的各种假设形成的假设空间中去搜索一个假设，这个假设对当前的数据拟合情况最好。</p><hr><h2 id="机器学习的三要素"><a href="#机器学习的三要素" class="headerlink" title="机器学习的三要素"></a>机器学习的三要素</h2><ol><li>模型</li><li>策略</li><li>算法</li></ol><hr><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>针对单个具体样本，表示模型预测值与真实样本值之间的差距。损失函数越小，说明模型对于该样本预测越准确。常见损失函数有0-1损失函数、平方损失函数、绝对损失函数、对数损失函数（对数似然损失函数）。</p><h3 id="常见的损失函数"><a href="#常见的损失函数" class="headerlink" title="常见的损失函数"></a>常见的损失函数</h3><p><img src="/images/20150323191253382.jpg" alt></p><hr><h2 id="经验风险和结构风险"><a href="#经验风险和结构风险" class="headerlink" title="经验风险和结构风险"></a>经验风险和结构风险</h2><p>确定了损失函数后，那么自然地损失函数越小越好，由于模型的输入X，输出Y 是随机变量，遵循联合分布P(X, Y)，所以损失函数的期望为：</p><p><img src="/images/8166116-bd9e4acdf2460fa2.png" alt></p><p>我们将上面提到的训练集的总损失定义为经验风险，如下所示：</p><p><img src="/images/8166116-207a3b5e00a4117b.png" alt></p><p>将损失的期望称为期望风险，如下所示：</p><p><img src="/images/8166116-bd9e4acdf2460fa2.png" alt></p><h3 id="怎样求风险？"><a href="#怎样求风险？" class="headerlink" title="怎样求风险？"></a>怎样求风险？</h3><p>机器学习问题求的是条件概率，那么有人就说了，既然上面提到了两随机变量的联合分布，那么我们根据条件概率-联合概率-边缘概率的关系岂不是可以直接求解？</p><p>其实，我们手头无法得到全体样本，因此，联合概率 P(X, Y) 是无法得到的，但是根据弱大数定律，当样本N无限大时，可用经验风险作为期望风险的估计，也就是局部估计整体。</p><p>那么我们常说的风险最小化其实就指的是经验风险最小化！</p><h3 id="为何引入结构化风险？"><a href="#为何引入结构化风险？" class="headerlink" title="为何引入结构化风险？"></a>为何引入结构化风险？</h3><p>虽然可以使用经验损失近似估计期望风险，但是大数定理的前提是N无穷大，实际上，我们的训练集一般不会特别大，此时就需要对经验风险做出适当调整才能近似估计。因此引入结构风险。</p><p>结构化风险是为了缓解数据集过小而导致的过拟合现象，其等价于正则化，本质上反应的是模型的复杂度。认为经验风险越小，参数越多，模型越复杂，因此引入对模型复杂度的惩罚机制。定义如下：</p><p><img src="/images/8166116-93d70fbaebad2b46.png" alt></p><p>正则化被定义为模型复杂度的单调函数，λ用于权衡经验风险与模型复杂度。<br>至此，我们认为结构风险最小化的模型是最优模型，因此，我们的优化问题变为：</p><p><img src="/images/8166116-88d3f8435e4c434a.png" alt></p><h3 id="结构化风险本质"><a href="#结构化风险本质" class="headerlink" title="结构化风险本质"></a>结构化风险本质</h3><p>结构化风险（正则项）其实是加入了模型参数分布的先验知识，也就是贝叶斯学派为了将模型往人们期望的地方去发展，继而加入了先验分布，由于是人为的先验，因此也就是一个规则项（这也就是正则项名称的由来）。这样一来，风险函数将进一步考虑了被估计量的先验概率分布。</p><hr><h2 id="参考资料和相关网址"><a href="#参考资料和相关网址" class="headerlink" title="参考资料和相关网址"></a>参考资料和相关网址</h2><p>经验风险、期望风险、结构风险:<br><a href="https://www.jianshu.com/p/903e35e1c95a" target="_blank" rel="noopener">https://www.jianshu.com/p/903e35e1c95a</a></p>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
